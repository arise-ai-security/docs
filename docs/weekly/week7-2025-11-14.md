# Research Sync 2025-11-14

**Attendees:** Caroline Cahill, In Keun Kim, Song Li

**Date:** 2025-11-14
---

## Summary

Our task is split into two sections:

1. **Engineering:** A flexible, decoupled platform built on the OpenHands SDK(or Claude Code) to enable rapid
   prototyping.
2. **Algorithm:** The first hypothesis we are building to test on this platform: the **Dynamic AI Task-Resolution Tree (
   DART)**.

**Current Status:** 游릭 On Track / 游리 Minor Obstacles / 游댮 Blocked

游릭 **On Track**:

游리 **Minor Obstacles**:

游댮 **Blocked**:

---

## Key Accomplishments This Week

### 1. Engineering: The Experiment Platform

#### Objective: Rapid Hypothesis Testing

The primary engineering goal is to create an "experiment platform" that enables "rapid hypothesis testing" using the *
*OpenHands SDK** and **Claude Code**.

**Why we are building this:**

* The `SecVerifier` architecture is tightly coupled with its paper's concepts, making it almost impossible to change
  control variables (e.g., model, temperature, number of agents, each agent's responsibility, etc.).
* We have many hypotheses for testing and need a flexible code architecture for this rapid prototyping of concepts.
* We have the modern OpenHands SDK and, despite some critical bugs, we have found effective workarounds.

#### Current Status (90% Complete)

* We have successfully cut the dependency between our repository and the original `Sec-Bench/Verifier` repo.
* The **only** remaining dependency is the "per-instance docker image setup," which we will continue to use.
* We can now **freely set models, filter instances on the go,** and re-architect agent workflows without being
  constrained by the old 3-phase-linear design.

## 2. Algorithm: Dynamic AI Task-Resolution Tree (DART)

The first major hypothesis we will test on this platform is the **Dynamic AI Task-Resolution Tree (DART)**. This model
moves away from `SecVerifier`'s linear pipeline to a recursive, self-correcting tree of AI agents.

### 2.1 Project Objective

To create a **Dynamic AI Task-Resolution Tree (DART)** platform. This system will autonomously manage a tree of
AI-driven "Nodes" to solve complex coding tasks provided by a Human Client (C). The system's "technical moat" is its
recursive, self-correcting ability to assess task complexity at each node, dynamically branching into parallel "solution
portfolios" to maximize the probability of success.

### 2.2 Core Components

* **Human Client (C):** The user who provides the initial, high-level task prompt.
* **Manager Agent (M) / Root Node ($N_0$):** The Layer 0 Node. This is the **most intelligent agent** in the system (
  e.g., GPT-5, Claude-Opus). Its sole purpose is to perform the initial task decomposition into a *sequential* list of
  high-level subtasks (Task_1, Task_2, ... Task_k).
* **Shared Data Repository (R):** Data repository. It holds the artifacts of all system. (i.e. ID of nodes, prompts, input/outputs, status etc). All successful work is eventually merged back here.
* **Task Node ($N_i$):** A *task-state* in the tree, representing a specific coding challenge (e.g., "Implement Task_1"). Each Node is defined by:
    * Its assigned task.
    * Its **Node State ($S_i$)**, which is a *forked branch* (a copy) of its parent's code repository.
* **Task Analyzer Agent (TAA):** A lightweight, low-cost AI model (e.g., Claude Sonnet, Gemini Pro). Its job is to
  service a Node by assessing its task's complexity. It executes the **"Moat" Prompt** (see Section 3.1).
* **Execution Agent (EA):** A high-capability, specialized coding AI (e.g., Claude Code, GPT-5, OpenHands). Its job is
  to perform the ATOMIC coding task, including **writing, testing, and validating** its own code.

### 2.3 Core Algorithm: The Node Lifecycle

This is the recursive logic that runs at **every Node ($N_i$)** in the tree, from $N_0$ (Manager) down.

1. **Receive Task:** Node $N_i$ receives a task from its parent, $N_{parent}$.
2. **Initialize State:** $N_i$ forks the repository state from $N_{parent}$, creating its own isolated branch, $S_i$.
3. **Task Assessment:** $N_i$ invokes a **Task Analyzer Agent (TAA)**.
    * **Input to TAA:** The task, the file-state $S_i$, and the Analyzer prompt.
    * **Output from TAA (JSON):** `{ "plan": "...", "classification": "ATOMIC|COMPOSITE" }`
4. **Decision Branch:**
    * **If `classification == "ATOMIC"`:** $N_i$ *becomes* a **Leaf Node**.
        * It invokes an **Execution Agent (EA)** to perform the task based on the `plan`.
        * The EA must write code, run linters, and **execute unit tests** within the $S_i$ state.
        * If tests pass, $N_i$ reports "SUCCESS" and its state $S_i$ up to its parent.
        * If tests fail, $N_i$ reports "FAILURE."
    * **If `classification == "COMPOSITE"`:** $N_i$ *becomes* a **Manager Node**.
        * It uses its TAA's `plan` to decompose its task into further sub-subtasks ($T_{i,1}$, $T_{i,2}$, ...).
        * It then proceeds to **Spawn Children** (see Section 2.4.3) for each sub-subtask.


### 2.4 Key Architectural Principles

#### 2.4.1 Principle: Recursive Complexity Assessment

The core logic of the system is the TAA's prompt. This prompt forces the AI to "code to think" by generating a
pseudocode plan. This plan is then used as the *justification* for its ATOMIC or COMPOSITE classification. This logic is
shared by all nodes, ensuring a consistent method of decomposition at every level.

#### 2.4.2 Principle: Path-State Isolation

Each path from the Root to a Node is computationally isolated. This functions like **Git**.

* **State:** The Node State ($S_i$) is a copy-on-write **fork** or **branch** of its parent's state. Work in one branch
  path (e.g., $N_0 \rightarrow N_1 \rightarrow N_{1,a}$) is not visible to its sibling path (
  e.g., $N_0 \rightarrow N_1 \rightarrow N_{1,b}$). They cannot see each other's changes.
* **History:** The "conversation history" is the path of tasks itself (e.g., Task_M $\rightarrow$ Task_1 $\rightarrow$
  Task_{1,a}). This ensures context is preserved without contamination.

#### 2.4.3 Principle: Parallel Portfolio Spawning (Hyperparameter Strategy)

This is our **Exploration Strategy**. When a Manager Node $N_i$ (for task $T_i$) spawns children for a
subtask ($T_{i,j}$), it spawns a *competing portfolio* of new Nodes ($N_{i,j,a}$, $N_{i,j,b}$, etc.).

**Example Portfolio (for one subtask):**

* **Node $N_{i,j,a}$ (The "Reliable"):** `model: gpt-5`, `temperature: 0.1` (Low-temp, best model)
* **Node $N_{i,j,b}$ (The "Creative"):** `model: gpt-5`, `temperature: 1.0` (High-temp, best model)
* **Node $N_{i,j,c}$ (The "Specialist"):** `model: claude-code`, `temperature: 0.2` (Specialized coding model)
* **Node $N_{i,j,d}$ (The "Fast/Cheap"):** `model: sonnet-4.5`, `temperature: 0.3` (Cheaper, faster model)

This is a **parallel race**. The first node in this portfolio to report "SUCCESS" wins.

#### 2.4.4 Principle: First-Success Termination

As soon as a "winning" path (e.g., $N_{i,j,a}$) reports "SUCCESS" to its parent ($N_i$), $N_i$ does two things:

1. **Terminates** all sibling portfolios (e.g., $N_{i,j,b}$, $N_{i,j,c}$) and their descendants to prevent wasted
   computation.
2. **Adopts** the winning state $S_{i,j,a}$ as its new state $S_i$.
3. Moves on to its next subtask (e.g., $T_{i, j+1}$).

### 2.5 High-Level System Workflow

1. **C $\rightarrow$ M:** Client submits the main problem.
2. **M (Node $N_0$):**
    * Invokes **TAA**. Gets `{"plan": "...", "classification": "COMPOSITE"}`.
    * Decomposes task into `Task_1`, `Task_2`, `Task_k`.
3. **M (for `Task_1`):**
    * Spawns a portfolio of Layer 1 Nodes ($N_{1,a}$, $N_{1,b}$, $N_{1,c}$) to solve `Task_1`.
    * Each L1 Node gets a *copy* of the initial repo state.
4. **Node $N_{1,a}$:**
    * Invokes **TAA**. Gets `{"plan": "...", "classification": "COMPOSITE"}`.
    * Decomposes its `Task_1` into `Task_{1,a,1}` and `Task_{1,a,2}`.
    * Spawns a portfolio of L2 Nodes (e.g., $N_{1,a,1,x}$, $N_{1,a,1,y}$) for the first sub-task.
5. **Node $N_{1,a,1,x}$:**
    * Invokes **TAA**. Gets `{"plan": "...", "classification": "ATOMIC"}`.
    * Invokes **EA**.
    * EA writes code, runs tests. **Tests PASS.**
    * $N_{1,a,1,x}$ reports "SUCCESS" to its parent, $N_{1,a}$.
6. **Propagation:**
    * $N_{1,a}$ receives success, terminates $N_{1,a,1,y}$ (the sibling), and adopts the new code state.
    * $N_{1,a}$ continues this process until all its subtasks are done, and it reports "SUCCESS" for `Task_1` up to **M
      **.
7. **M:**
    * Receives "SUCCESS" from $N_{1,a}$.
    * **Terminates** all other L1 Nodes ($N_{1,b}$, $N_{1,c}$) and their entire sub-trees.
    * **Merges** the successful code state from $N_{1,a}$'s path into the **main branch** of `R`.
8. **Repeat:** M now starts this entire process over for `Task_2`, working from the newly updated "main" branch.
9. **M $\rightarrow$ C:** After `Task_k` is complete, M reports the final, fully-coded result to the Client.

---

## 3. Core Agent Definitions & Prompts

This section contains the precise definitions and prompts that form the core of the DART algorithm.

### 3.1 Terminology: Node vs. Agent

* **Node:** A **Node** is a *task* or *problem state* in the tree.
* **Agent:** An **Agent** (like a `TaskAnalyzer` or `Executor`) is an AI model that *services* a Node to move it to a
  new state.
