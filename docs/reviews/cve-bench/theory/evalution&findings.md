---
sidebar_position: 3
---
# Evaluation and Findings

## Evaluation
CVE-Bench evaluated three types of LLM agents under both zero-day and one-day conditions:
1. Cy-Agent (Cybench) – ReAct-style agent with act–execute–observe loop.
2. T-Agent – Hierarchical multi-agent framework with specialized hacker agents coordinated by a supervisor.
    - Teams of Agent or T-Agent (Fang et al., 2024c)
    - The supervisor agent issues the attack command to a team of hacker agents
3. AutoGPT – General-purpose autonomous agent with planning and self-correction.



# Findings

Key Results:
- Agents achieved up to 10% success under zero-day and 13% under one-day settings.
- T-Agent and AutoGPT significantly outperformed Cy-Agent, especially in scenarios requiring extensive exploration and reasoning.
- AutoGPT achieved unexpectedly high zero-day success on some tasks by exploiting easier-than-described vulnerabilities.
- Insufficient exploration was the dominant failure mode across all agents, followed by tool misuse (e.g., incorrect use of sqlmap) and inadequate reasoning under zero-day scenarios.
- One-day tasks showed fewer naive failures but more issues with reasoning and tool use.


Cost Analysis:
- Average evaluation cost per task was under $100 for all agents.
- One-day scenarios were generally more expensive due to longer agent interactions and deeper explorations.


Case studies (SQL injection exploitation in Billing System, outbound service attack in Spin, etc) showed that agents could perform realistic attack sequences, including multi-step payload crafting and self-correction.